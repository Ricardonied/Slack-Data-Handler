# Script that produces a detailed CSV of Slack messages with
# additional metadata (threads, reactions, etc.) and exports
# users and channels information. Useful for research purposes.

# Install the packages required to read the Slack export. Uncomment
# the following lines if running for the first time.
install.packages("rjson")
library(rjson) # import and manipulate JSON files
install.packages("dplyr")
library(dplyr) # data handling / pipe operator

# Unzip your Slack export and place the extracted folder somewhere on
# your machine (e.g. `C:/Users/User/Documents`). Use `getwd()` if you
# need to set the working directory.
# Provide the folder name via argument or a default will be used when
# running non-interactively.
args <- commandArgs(trailingOnly = TRUE)
if (interactive()) {
  export_name <- if (length(args) >= 1) args[1] else readline("Enter Slack export folder name: ")
} else {
  export_name <- if (length(args) >= 1) args[1] else "my_export_folder"
}
working_directory <- getwd() %>% as.character()
slackexport_folder_path <- paste0(working_directory, "/", export_name)

# Build a table of all channels in the export. These details are
# available in `<export_name>/channels.json`.
channels_path <- paste0(slackexport_folder_path,"/channels.json")
channels_json <- fromJSON(file = channels_path)
channel_list <- setNames(data.frame(matrix(ncol = 9, nrow = 0)), 
                         c("ch_id", "name", "created", "creator", "is_archived",
                           "is_general", "members", "topic", "purpose"))

for (channel in 1:length(channels_json)) {
  # Populate `channel_list` with information about each channel from the JSON file
  channel_list[channel, "ch_id"] <- channels_json[[channel]]$id
  channel_list[channel, "name"] <- channels_json[[channel]]$name
  channel_list[channel, "created"] <- channels_json[[channel]]$created
  channel_list[channel, "creator"] <- channels_json[[channel]]$creator
  channel_list[channel, "is_archived"] <- channels_json[[channel]]$is_archived
  channel_list[channel, "is_general"] <- channels_json[[channel]]$is_general
  
  # Build a comma-separated list of member IDs
  memberlist <- ""
  if (length(channels_json[[channel]]$members) > 0) { # check that the member list is not empty
    for (member in 1:length(channels_json[[channel]]$members)) {
      # If it isn't the last member
      if (member < length(channels_json[[channel]]$members)) {
        memberlist <- paste0(memberlist, channels_json[[channel]]$members[[member]], ", ")
      }
      if (member == length(channels_json[[channel]]$members)) {
        memberlist <- paste0(memberlist, channels_json[[channel]]$members[[member]])
      }
    }
  }
  channel_list[channel, "members"] <- memberlist
  channel_list[channel, "topic"] <- channels_json[[channel]]$topic$value
  channel_list[channel, "purpose"] <- channels_json[[channel]]$purpose$value
  
  # For each channel list all JSON files (one per day) and store the
  # list into `channels_json[[channel]]$dayslist`
  channel_folder_path <- ""
  channels_json[[channel]]$dayslist <- ""
  channel_folder_path <- paste0(slackexport_folder_path,"/",channel_list[channel,"name"])
  channels_json[[channel]]$dayslist <- list.files(channel_folder_path, 
                                                  pattern=NULL, all.files=FALSE, full.names=FALSE)
}

# Helper to transform a single JSON file into a data frame with the
# desired message metadata
slack_json_to_dataframe <- function(slack_json) {
  # Start the data frame with the expected columns
  messages_df <- setNames(data.frame(matrix(ncol = 10, nrow = 0)), 
                          c("msg_id", "ts", "user", "type", "text", "reply_count",
                            "reply_users_count", "ts_latest_reply", "ts_thread", 
                            "parent_user_id"))
  
  # Itera sobre cada mensagem no arquivo JSON
  for (message in 1:length(slack_json)) {
    # Extract fields while replacing NULL with NA
    msg_id <- if (!is.null(slack_json[[message]]$client_msg_id)) slack_json[[message]]$client_msg_id else NA
    ts <- if (!is.null(slack_json[[message]]$ts)) slack_json[[message]]$ts else NA
    user <- if (!is.null(slack_json[[message]]$user)) slack_json[[message]]$user else NA
    type <- if (!is.null(slack_json[[message]]$type)) slack_json[[message]]$type else NA
    text <- if (!is.null(slack_json[[message]]$text)) slack_json[[message]]$text else NA
    reply_count <- if (!is.null(slack_json[[message]]$reply_count)) slack_json[[message]]$reply_count else NA
    reply_users_count <- if (!is.null(slack_json[[message]]$reply_users_count)) slack_json[[message]]$reply_users_count else NA
    ts_latest_reply <- if (!is.null(slack_json[[message]]$latest_reply)) slack_json[[message]]$latest_reply else NA
    ts_thread <- if (!is.null(slack_json[[message]]$thread_ts)) slack_json[[message]]$thread_ts else NA
    parent_user_id <- if (!is.null(slack_json[[message]]$parent_user_id)) slack_json[[message]]$parent_user_id else NA
    
    # Append the message record to the data frame
    messages_df <- rbind(messages_df, data.frame(
      msg_id = msg_id, 
      ts = ts, 
      user = user, 
      type = type, 
      text = text, 
      reply_count = reply_count, 
      reply_users_count = reply_users_count, 
      ts_latest_reply = ts_latest_reply, 
      ts_thread = ts_thread, 
      parent_user_id = parent_user_id,
      stringsAsFactors = FALSE
    ))
  }
  
  return(messages_df)
}

# Inicializa o dataframe final para armazenar todas as mensagens de todos os canais
all_channels_all_files_df <- setNames(data.frame(matrix(ncol = 11, nrow = 0)), 
                                      c("msg_id", "ts", "user", "type", "text",
                                        "reply_count", "reply_users_count", 
                                        "ts_latest_reply", "ts_thread", "parent_user_id",
                                        "channel"))

# Loop para processar cada canal
for (channel in 1:length(channels_json)) {
  # Create a data frame to hold all messages for a single channel
  all_channel_files_df <- setNames(data.frame(matrix(ncol = 10, nrow = 0)), 
                                   c("msg_id", "ts", "user", "type", "text",
                                     "reply_count", "reply_users_count", 
                                     "ts_latest_reply", "ts_thread", "parent_user_id"))
  
  # Check if the list of daily files is not empty
  if (length(channels_json[[channel]]$dayslist) > 0) {
    for (file_day in 1:length(channels_json[[channel]]$dayslist)) {
      # Load the JSON file for a specific day
      parentfolder_path <- paste0(slackexport_folder_path,"/",channels_json[[channel]]$name)
      filejson_path <- paste0(parentfolder_path, "/", channels_json[[channel]]$dayslist[[file_day]])
      import_file_json <- fromJSON(file = filejson_path)
      
      # Convert the JSON file to a data frame using `slack_json_to_dataframe`
      import_file_df <- slack_json_to_dataframe(import_file_json)
      
      # Append the day's messages to the channel data frame
      all_channel_files_df <- rbind(all_channel_files_df, import_file_df)
    }
    
    # Add the channel name to the data frame
    all_channel_files_df$channel <- channels_json[[channel]]$name
    
    # Append the channel data to the master data frame with all channels
    all_channels_all_files_df <- rbind(all_channels_all_files_df, all_channel_files_df)
  } else {
    # Warn if the channel had no associated JSON files
    warning(paste("Channel", channels_json[[channel]]$name, "has no JSON files."))
  }
}



# Write all messages to a CSV in the working directory.
# File name uses the earliest and latest timestamps found.
filename_mindate <- min(all_channels_all_files_df$ts) %>% as.numeric() %>% as.Date.POSIXct()
filename_maxdate <- max(all_channels_all_files_df$ts) %>% as.numeric() %>% as.Date.POSIXct()
# `export_name` was defined earlier before reading any files
slack_export_df_filename <- paste0(export_name,"_",filename_mindate,"_to_",filename_maxdate,".csv")
write.csv(all_channels_all_files_df, file = slack_export_df_filename)

#TODO - how does it handle orphaned threads? or deleted children? 
#TODO - make a users table with user metadata, write to csv
users_path <- paste0(slackexport_folder_path,"/users.json")
users_json <- fromJSON(file = users_path)
# Initialize empty user data frame
user_list_df <- setNames(data.frame(matrix(ncol = 11, nrow = 0)), 
                         c("user_id", "team_id", "name", "deleted", "real_name",
                           "tz", "tz_label", "tz_offset", "title", "display_name", 
                           "is_bot"))
# Fill it with fields from the `users.json` file
for (user in 1:length(users_json)) {
  user_list_df[user, "user_id"] <- users_json[[user]]$id
  user_list_df[user, "team_id"] <- users_json[[user]]$team_id
  user_list_df[user, "name"] <- users_json[[user]]$name
  user_list_df[user, "deleted"] <- users_json[[user]]$deleted
  # real_name is located under $profile for bots
  if (is.null(users_json[[user]]$real_name) == FALSE) {
    user_list_df[user, "real_name"] <- users_json[[user]]$real_name
  }
  if (is.null(users_json[[user]]$profile$real_name) == FALSE) {
    user_list_df[user, "real_name"] <- users_json[[user]]$profile$real_name
  }
  user_list_df[user, "title"] <- users_json[[user]]$profile$title
  user_list_df[user, "display_name"] <- users_json[[user]]$profile$display_name
  user_list_df[user, "is_bot"] <- users_json[[user]]$is_bot
  # Bots (and maybe others) might not have time zone information
  if (is.null(users_json[[user]]$tz) == FALSE) {
    user_list_df[user, "tz"] <- users_json[[user]]$tz
    user_list_df[user, "tz_label"] <- users_json[[user]]$tz_label
    user_list_df[user, "tz_offset"] <- users_json[[user]]$tz_offset
  }
  
}
#write user data to a csv to be read back in as df, as needed.
slack_export_user_filename <- paste0(export_name,"_users.csv")
write.csv(user_list_df, file = slack_export_user_filename)


# Finally, write out the channel metadata as a separate CSV
slack_export_channel_filename <- paste0(export_name,"_channels.csv")
write.csv(channel_list, file = slack_export_channel_filename)

